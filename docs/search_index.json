[
["integracion-de-formas-diferenciales.html", "Capítulo 12 Integración de formas diferenciales 12.1 Integración 12.2 Aplicaciones primitivas 12.3 Cambio de variables 12.4 Formas diferenciales 12.5 Cadenas y símplices 12.6 Teorema de Stoke 12.7 Formas cerradas y formas exactas 12.8 Análisis vectorial", " Capítulo 12 Integración de formas diferenciales Una forma diferencial es una funcion escalar definida en un abierto de \\(\\real^n\\) \\[\\appl{f}{\\Omega\\subset\\real^N}{\\real}\\] Operaciones habituales: Sea \\(\\mathcal{C} = \\{e_1,e_2,...,e_n\\}\\) la base canónica en \\(\\real^N\\). Sea \\(L\\) una aplicación lineal \\[\\appl{L}{\\real^N}{\\real}\\] Que recordamos que cumplen: \\[ L(\\gx+\\gy) = L(\\gx)+L(\\gy); L(\\lambda\\gx) = \\lambda L(\\gx)\\] Definimos \\(\\gy\\in\\real^N \\leadsto \\gy = \\displaystyle\\sum_1^n y_i e_i\\), con lo que \\[L(\\gy) = \\sum y_i L(e_i)\\] Entonces \\[\\left.\\begin{array}{cc} v_i = L(e_i)\\\\ y_i = P_i(\\gy) \\end{array}\\right\\} \\rightarrow L(\\gy) = \\sum_i v_iP_i(y)\\] Siendo \\(P_i\\) las proyecciones, una base del espacio dual. \\(P_i \\equiv dx_i\\). \\(dx_i[\\gy] \\equiv P_i(\\gy) = y_i\\) Entonces, dado un \\(\\gv\\) podemos construir \\[L \\equiv \\sum_i^N v_idx_i\\] \\[L[\\gy] = \\sum_i^N v_idx_i[\\gy] = \\sum_i^N v_iy_i\\] Indicaremos con paréntesis el punto en el que estamos evaluando, y con corchetes el punto en el que estamso actuando. Supongamos \\(f\\) una función escalar (una 0-forma). \\[\\grad f(\\gx) = \\left( \\dpa{f}{x_i}(\\gx)\\right)\\, i=1,...,N\\] Nos podemos construir una 1-forma desde el gradiente \\[\\dpa{f}{x_i}(\\gx)dx_i \\] A esta 1-forma en particular la llamaremos \\(df(\\gx)\\). ¿Utilidad? Ya la veremos, pero es una forma de escribir el producto escalar. \\[\\pesc{\\grad f(\\gx),\\gy} = df(\\gx)[\\gy]\\] Punto de partida: Aplicaciones \\[\\appl{\\Phi}{\\real^N\\x\\real^N}{\\real}\\] Que cumplen Consecuencias: en \\(\\real^3\\) para facilitar las cuentas. \\[\\Phi(\\gu,\\gv) = \\Phi(u_1e_1+u_2e_2+u_3e_3,v_1e_1+v_2e_2+v_3e_3)\\] Aplicando las propiedades anteriores obtenemos: \\[\\begin{gather*} \\overbrace{u_1v_1\\Phi(e_1,e_1)}^{\\equiv 0} + u_1v_2\\Phi(e_1,e_2) + u_1v_3+\\Phi(e_1,e_3)+\\\\ u_2v_1+\\Phi(e_2,e_1)+u_2v_2+\\Phi(e_2,e_2)+u_2v_3+\\Phi(e_2,e_3)+\\\\ u_3v_1\\Phi(e_3,e_1)+u_3v_2+\\Phi(e_3,e_2)+u_3v_3+\\Phi(e_3,e_3) = \\\\ \\underbrace{(u_1v_2-u_2v_1)}_{\\left|\\begin{matrix} u_1&amp;u_2\\\\v_1&amp;v_2 \\end{matrix}\\right|}\\overbrace{\\Phi(e_1,e_2)}^{C_1}+(u_1v_3-u_3v_1)\\Phi(e_1,e_3)+(u_2v_3-u_3v_2)\\Phi(e_2,e_3) \\end{gather*}\\] Hemos demostrado que \\[\\Phi(\\gu,\\gv) = C_1B_{12}(\\gu,\\gv) + C_2B_{13}(\\gu,\\gv) + C_3B_{23}(\\gu,\\gv)\\] \\(B_{ij} = dx_i\\y dx_j\\) \\[dx\\y dx_j [\\gu,\\gv] = \\det \\begin{pmatrix} u_i&amp;u_j\\\\v_i&amp;v_j \\end{pmatrix} = \\det \\begin{pmatrix} dx_i[\\gu]&amp;dx_j[\\gu]\\\\dx_[\\gv]&amp;dx_j[\\gv] \\end{pmatrix}\\] Vamos a dar una definición general de una k-forma. Elementos básicos: \\[\\dfl{x_{i_1}}{x_{i_k}}[\\gu^1,\\gu^2,...,\\gu^k] = \\det\\begin{pmatrix} u_{i_1}^1 &amp; ... &amp; u_{i_k}^1\\\\ \\vdots &amp; \\ddots &amp; \\vdots\\\\ u_{i_1}^k &amp; ... &amp; u_{i_k}^k \\end{pmatrix}\\] Esto nos dice que en \\(\\real^N\\), teniendo \\(K\\)-formas (con \\(K&lt;N\\)) tenemos \\(\\comb{N}{K}\\) combinaciones distintas. Si \\(K&gt;N\\) y \\(\\omega\\) es una k-forma, entonces \\(\\omega \\equiv 0\\) En \\(\\real^3\\). Al cambio en la 2-forma, que es \\(dzdx\\). Esto es para seguir el (por temas de la orientación). Esto es \\(x\\to y \\to z \\to x\\) Las las podemos interpretar como 0-formas y como 3-formas. Los los podemos interpretar como 1-formas y también como 2-formas. Para escribir un conjunto de subíndices \\(\\{i_1,i_2,...,i_k\\} \\equiv I\\) También acortaremos \\(\\dfl{x_{i_1}}{x_{i_k}} \\equiv dx_I\\). La definición quedaría \\(\\displaystyle \\sum_I F_I(\\gx)dx_I\\) Siempre se puede multiplicar por 0-formas y sumar formas del mismo orden. Estas operaciones son triviales porque son operaciones internas. Vamos a definir las operaciones externas: Si \\(K+S&gt;N \\implies \\omega\\y\\beta=0\\) Vamos a por un ejemplo de producto exterior en \\(ℝ^3\\). Consideramos las dos siguientes formas diferenciales: \\[\\begin{gather*} \\omega = f_1(x,y,z)\\df x + f_2(x,y,z)\\df y + f_3(x,y,z) \\df z \\\\ \\beta= g_1(x,y,z)\\df x + g_2 (x,y,z) \\df y + f_3 (x,y,z) \\df z \\end{gather*}\\] y calculamos su producto exterior, \\(\\omega\\y\\beta\\) \\[\\begin{multline*} \\omega\\y\\beta = f_1g_1\\df{x,x} + f_1g_2\\df{x,y} + f_1g_3\\df{x,z} + f_2g_1\\df{y,x} +\\\\ + f_2g_2\\df{y,y}+ f_2g_3\\df{y,z} + f_3g_1\\df{z,x}+f_3g_2\\df{z,y}+f_3g_3\\df{z,z} \\end{multline*}\\] Tachamos los que sean 0 (\\(\\df{x,x} = 0\\)) y tenemos cuidado con el orden cíclico, y nos queda \\[ (f_2g_3-f_3g_2)\\df{y,z} + (f_3g_1-f_1g_3)\\df{z,x} + (f_1g_2 - f_2g_1) \\df{x,y} \\] Partiendo de 2 campos vectoriales que eran 1-formas hemos llegado a una 2-forma. Además, si nos fijamos, hemos llegado a la definición de en \\(ℝ^3\\): \\[ \\overrightarrow{F} \\x \\overrightarrow{G} = \\left((f_2g_3-f_3g_2),(f_3g_1-f_1g_3),(f_1g_2 - f_2g_1)\\right) \\] El diferencial exterior trata de ampliar el concepto del diferencial (la matriz de derivadas parciales) más allá de las funciones, de tal forma que podamos aplicarlo a formas diferenciales. Veamos algunos ejemplos, empezando en \\(ℝ^3\\). Partimos de un campo vectorial \\(G = (g_1,g_2,g_3)\\) al que asociamos una 2-forma \\(ω\\): \\[ \\omega = g_1 \\df{y,z} + g_2 \\df{z,x} + g_3 \\df{x,y} \\] Calculamos ahora la diferencial exterior, \\(\\dif\\omega\\). Para calcularla, recordamos que \\(\\df{x,x} = 0\\) y que podemos cambiar el orden del producto exterior si respetamos el orden cíclico (\\(x,y,z\\)). \\[\\begin{align*} \\dif\\omega &amp;= \\df{g_1,y,z} + \\df{g_2,z,x} + \\df{g_3,x,y} = \\\\ &amp;= \\left(\\dpa{g_1}{x} \\df x + \\dpa{g_1}{y} \\df y + \\dpa{g_1}{z}\\df z \\right)\\y \\df{y,z}\\\\ &amp;\\qquad + \\left(\\dpa{g_2}{x} \\df x + \\dpa{g_2}{y} \\df y + \\dpa{g_2}{z}\\df z \\right)\\y \\df{z,x}\\\\ &amp;\\qquad + \\left(\\dpa{g_3}{x} \\df x + \\dpa{g_3}{y} \\df y + \\dpa{g_3}{z}\\df z \\right)\\y \\df{x,y} = \\\\ &amp;= \\dpa{g_1}{x}\\df{x,y,z} + \\dpa{g_2}{y}\\df{y,z,x} + \\dpa{g_3}{z}\\df{z,x,y} = \\\\ &amp;= \\left(\\dpa{g_1}{x} + \\dpa{g_2}{y} + \\dpa{g_3}{z}\\right)\\df{x,y,z} \\end{align*}\\] Hemos llegado a una 3-forma que además es la forma diferencial asociada a la de \\(G\\). Pasamos a otro ejemplo, donde vamos a calcular la diferencial exterior de una 1-forma \\(ω=F_1\\df x + F_2 \\df y + F_3 \\df z\\). Recordamos que si invertimos el orden del producto exterior pagamos con un cambio de signo, esto es, \\(\\df{x,z} = - \\df{z,x}\\). \\[\\begin{align*} \\dif ω &amp;= \\dif\\left(F_1\\df x + F_2\\df y+F_3\\df z\\right) =\\\\ &amp;= \\df{F_1,x} + \\df{F_2,y} + \\df{F_3,z} = \\\\ &amp;= \\left(\\dpa{F_1}{x}\\df x + \\dpa{F_1}{x}\\df y + \\dpa{F_1}{x}\\df z \\right)\\y \\df x + \\left(\\dpa{F_2}{x}\\df x + \\dpa{F_2}{x}\\df y + \\dpa{F_2}{x}\\df z \\right)\\y \\df y + \\\\ &amp; \\qquad \\qquad + \\left(\\dpa{F_3}{x}\\df x + \\dpa{F_3}{x}\\df y + \\dpa{F_3}{x}\\df z \\right)\\y \\df z = \\\\ &amp;= \\left(\\dpa{F_3}{y} - \\dpa{F_2}{z} \\right)\\df{y,z} + \\left(\\dpa{F_1}{z} - \\dpa{F_3}{dx}\\right)\\df{z,x} + \\left(\\dpa{F_2}{x} - \\dpa{F_1}{y}\\right) \\df{x,y} \\end{align*}\\] Nos ha quedado un campo de la forma: \\[\\left(\\left(\\dpa{F_3}{y} - \\dpa{F_2}{z} \\right) ,\\left(\\dpa{F_1}{z} - \\dpa{F_3}{x}\\right),\\left(\\dpa{F_2}{x} - \\dpa{F_1}{y}\\right)\\right)\\] que coincide con el . \\(\\dif(\\omega + \\beta) = \\dif\\omega + \\dif\\beta\\) Siendo \\(\\omega = \\sum_I F_I \\dif x_I\\) una k-forma, \\(f\\) una 0-forma, tenemos que \\[ f\\omega = \\sum_I fF_I\\dif x_I \\] y entonces \\[ \\dif (f\\omega) = \\sum_I \\df{(fF_I),x_I} \\] , donde \\[ \\dif (fF_I) = \\sum_{j=1}^N \\dpa{fF_I}{x_j} \\df x_j = \\sum_{j=1}^N\\dpa{f}{x_j} F_I \\df x_j + \\sum_{j=1}^N\\dpa{F_I}{x_j} f \\df x_j = F_I \\dif f + f \\dif F_I \\] De esta forma, nos queda que \\[\\begin{align*} \\dif (fω) &amp;= \\sum_I \\left(F_I \\dif f + f \\dif F_I\\right)\\y \\dif x_I = \\\\ &amp;= \\sum_I F_I \\df{f,x_I} + \\sum_I f \\df{F_I,x_I} = \\\\ &amp;= \\sum_I \\dif f \\y F_I \\dif x_I + f \\dif ω = \\\\ &amp;= \\dif f \\y \\left(\\sum_I F_I \\dif x_I\\right) + f \\dif ω = \\\\ &amp;= ω \\df{f} + f \\dif ω \\end{align*}\\] Hemos llegado a una expresión similar a la de la derivada de un producto de funciones \\[d(f\\omega) = ω \\df{f} + f \\dif ω \\] Sean dos k-formas diferenciales \\(ω\\) y \\(β\\): \\[ \\omega =\\sum f_i \\df x_i ;\\; \\beta = \\sum_j g_j\\df x_j \\] Calculamos el diferencial de su producto exterior: \\[\\begin{align*} \\dif (\\omega \\y \\beta) &amp;= \\dif\\left(\\sum_{i,j=1}^N f_ig_jdx_y\\y dx_j\\right) =\\\\ &amp;= \\sum_{i,j=1}^N \\df{(f_ig_j),x_i,x_j} = \\\\ &amp;= \\sum_{i,j=1}^N \\left(\\sum_{k=1}^N \\dpa{(f_ig_j)}{x_k} \\dif x_k\\right)\\y \\df{x_i,x_j} = \\\\ &amp;= \\sum_{i,j,k=1}^N \\left(\\dpa{f_i}{x_k}g_j + f_i\\dpa{g_j}{x_k}\\right) \\df{x_k,dx_i,dx_j} = \\\\ &amp;= \\sum_{i,j,k=1}^N \\dpa{f_i}{x_k}g_j \\df{x_k,dx_i,dx_j}+ \\sum_{i,j,k=1}^N f_i\\dpa{g_j}{x_k}\\df{x_k,dx_i,dx_j} \\end{align*}\\] Ahora tratamos de encontrar \\(ω\\) y \\(β\\) en ese engendro para volver a una expresión más agradable: \\[\\begin{align*} \\dif (\\omega \\y \\beta) &amp;= \\sum_{i,j,k=1}^N \\dpa{f_i}{x_k}g_j \\df{x_k,x_i,x_j} + \\sum_{i,j,k=1}^N f_i\\dpa{g_j}{x_k}\\df{x_k,dx_i,dx_j} \\\\ &amp;= \\sum_{i,j,k=1}^N \\dpa{f_i}{x_k}\\df{x_k,x_i}\\y(g_j\\df x_j) + \\sum_{i,j,k=1}^N\\dpa{g_j}{x_k}\\df{x_k} \\y f_i \\df{x_i,dx_j} = \\\\ &amp;= \\sum_{i} \\left(\\sum_k \\dpa{f_i}{x_k}\\df{x_k}\\right) \\y \\dif x_i \\y \\left(\\sum_j g_j\\dif x_j\\right) \\\\ &amp;\\qquad + \\sum_{j} \\left(\\sum_k \\dpa{g_j}{x_k}\\df{x_k}\\right) \\y \\left(\\sum_i f_i\\dif x_i\\right) \\y \\dif x_j = \\\\ &amp;= \\sum_i \\df{f_i,x_i} \\y β + \\sum_j \\df{g_j} \\y ω \\y \\dif x_j = \\\\ &amp;= \\left(\\sum_i \\df{f_i,x_i}\\right) \\y β - ω \\y \\left(\\sum_j \\df{g_j,x_j}\\right) = \\\\ &amp;= \\dif ω \\y β - ω \\y \\dif β \\end{align*}\\] Entonces, si \\(\\omega,\\beta\\) son 1-formas tenemos que \\(\\dif(\\omega \\y \\beta) = \\dif\\omega \\y \\beta - \\omega \\y\\dif\\beta\\). Si por el contrario tuviésemos que \\(\\omega\\) es una k-forma y \\(\\beta\\) una s-forma, repitiendo las cuentas de nuevo llegaríamos a \\[\\dif \\omega \\y \\beta + (-1)^k \\omega \\y \\dif\\beta\\] Sea \\(\\omega\\) k-forma con coeficientes \\(C^2\\). Entonces, \\[ \\dif (\\dif ω) = 0 \\] Resumiendo las propiedades del diferencial: Partiendo de un campo en \\(\\real^3\\), podemos interpretarlo como una 1-forma o como una 2-forma. Queremos saber cómo llevar k-formas de \\(\\real^N\\) a \\(\\real^M\\). Partimos de la base de que existe una transformación \\(\\appl{T}{ℝ^N}{ℝ^M}\\) tal que \\(T(s)=x\\), y buscamos otra aplicación \\(\\appl{\\pb}{\\real^M}{\\real^N}\\). En caso de 0-formas, el es lo mismo que la composición. Es decir, dada una función \\(\\appl{f}{ℝ^M}{ℝ}\\), \\(\\pb f = f \\circ T\\). Basándonos en esta misma idea sobre las funciones escalares, vamos a tratar de hallar el pullback para las formas diferenciales. Supongamos que tenemos una k-forma \\(\\omega\\) en \\(\\real^M\\). Queremos construir \\(T^{\\ast}\\) en términos de \\(T\\) y \\(\\omega\\). Partimos de \\(\\gor{s} \\in \\real^N\\) (el punto donde se evalúa la k-forma), y \\(\\gv_1,\\gv_2,..,\\gv_k\\) los vectores en \\(\\real^N\\) sobre los que actúa \\(ω\\). Entonces \\[ (T^{\\ast}\\omega)(\\gor{s}) [\\gv_1,\\dotsc,\\gv_k] = \\omega(\\underbrace{T(s)}_{\\in\\real^M}) [\\underbrace{DT(s)\\gv_j}_{\\in\\real^M}] \\] Es decir, transformamos el punto en el que se evalúa \\(ω\\), que pasa a ser \\(T(\\gor{s})\\) en lugar de \\(\\gor{s}\\), y los vectores sobre los que actúa también los “movemos” usando la matriz diferencial. Vemos que \\[\\omega(T(s)) [DT(s)\\gv]\\equiv \\sum f_i(T(s))\\dif x_i[DT(s)\\gv]\\] \\[DT(s) = \\begin{pmatrix} \\dpa{T_1}{s_1}(s) &amp; ... &amp; \\dpa{T_1}{s_N}\\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\dpa{T_M}{s_1} &amp; \\dots &amp; \\dpa{T_M}{s_N} \\end{pmatrix} \\cdot \\begin{pmatrix} v_1\\\\ \\downarrow\\\\ v_N \\end{pmatrix}\\] ¿Que significa \\(\\dif x_i[DT(s)\\gv]\\)? Vamos a ver que pasa con el producto de una de las filas de la matriz. \\[\\df{x_i} [DT(s)\\gv] = \\dpa{T_i}{s_1}v_1 + ... + \\dpa{T_i}{s_N}v_n\\] Podemos darnos cuenta de que \\(v_1 = \\dif s_1[\\gv]\\). Con esto tenemos: \\[\\df{x_i} [DT(s)\\gv] = \\left(\\dpa{T_i}{s_1}\\dif s_1 + ... + \\dpa{T_i}{s_N}\\dif s_N \\right)[\\gv] = \\dif T_i [\\gv] \\] y por lo tanto \\[ (\\pb ω)(\\gor{s})[\\sample[\\gor{v}][k]] = \\omega(T(s)) [DT(s)\\gv] = \\sum f_i (T(s)) \\dif T_i [\\gv] \\] Sea \\(f(x)\\dif x_i\\) una 1-forma de la que queremos calcular el \\[T^{\\ast}(f\\dif x_i)(s)[v] = f(T(s)) \\dif x_1[DT(s)\\gv]\\] Supongamos \\(f\\equiv 1\\) \\[T^{\\ast}(fdx_i)(s)[v] = \\dif x_1[DT(s)\\gv] = \\dif T_i[\\gv]\\] \\(T^{\\ast}\\dif x_i = \\dif T_i\\). Sea \\(\\omega = \\sum_i f_i \\dif x_i\\) una 1-forma de la que queremos calcular el \\[ (T^{\\ast} \\omega )(s)[\\gv]= \\sum_i f_i(T(s))\\dif x_i [DT(s)\\gv] = \\sum_i f_i(T(s)) \\dif T_i [\\gv ] = T^{\\ast} (\\sum_i f_i \\dif x_i ) = \\sum_i f_i \\circ T \\dif T_i \\] \\(T^{\\ast} (\\sum_i f_i\\dif x_i) = \\sum_i (f_i \\circ T) \\dif T_i\\) ¿Cómo se comporta con el producto exterior? Vamos a trabajar con \\(f\\equiv 1\\). \\[\\begin{gather*} T^{\\ast}(\\df{x_i,x_j} [\\gu,\\gv] = \\df{x_i,x_j} \\left[DT(s)[\\gu], DT(s)[\\gv]\\right] = \\\\ = \\left|\\begin{matrix} \\dif x_i[DT(s)\\gu] &amp; \\dif x_j[DT(s)\\gu] \\\\ \\dif x_i[DT(s)\\gv] &amp; \\dif x_j[DT(s)\\gv] \\end{matrix}\\right| = \\left| \\begin{matrix} \\dif T_i[\\gu] &amp; \\dif T_j[\\gu]\\\\ \\dif T_i[\\gv] &amp; \\dif T_j[\\gv] \\end{matrix}\\right| \\stackrel{(1)}{=} \\df{T_i,T_j} [\\gu,\\gv] \\end{gather*}\\] (1): Por las propiedades del producto exterior de 1-formas. \\(T^{\\ast} (dx_i \\y dx_j) = dT_i \\y dT_j\\). ¿Qué pasa cuando tenemos el producto de 2-formas generadas? \\[\\omega = \\sum f_idx_i\\,;\\,\\beta=\\sum g_jdx_j\\] Vamos con el producto exterior. \\[\\begin{gather*} T^{\\ast} (\\omega \\y \\beta) (s) [\\gu,\\gv] = \\sum_{i,j} f_i(T(s))g_j(T(s)) \\underbrace{\\df{x_i,x_j} [DT(s)\\gu, DT(s),\\gv]}_{\\text{Calculado justo arriba}}\\\\ = \\sum_{i,j} (f_i\\circ T) = \\dotsb \\\\ = \\left(\\sum (f_i\\circ T)\\dif T_i\\right)\\y\\left(\\sum(g_j \\circ T) \\dif T_j\\right) = T^{\\ast}\\omega \\y T^{\\ast}\\beta \\end{gather*}\\] \\(T^{\\ast}(\\omega \\y \\beta) = T^{\\ast}\\omega \\y T^{\\ast}\\beta\\). Esto es válido para multiíndices \\(I\\), es decir, para \\(\\omega\\) k-forma y \\(\\beta\\) s-forma. Una vez visto cómo se comporta el respecto del producto exterior vamos a ver como se comporta con respecto de la diferencial exterior. \\[\\begin{gather*} \\dif (T^{\\ast} \\omega) = \\dif \\left(\\sum_i f_i(T(s)) \\dif x_i [DT(s)\\gv]\\right) = \\dif\\left(\\sum (f_i \\circ T)(s) \\dif T_i[\\gv]\\right)\\\\ = \\sum_i \\dif(f_i\\circ T)\\y dT_i \\end{gather*}\\] Vamos a ver qué significa \\(\\dif(f_i\\circ T)\\): \\[\\begin{gather*} \\dif (f_i\\circ T) = \\sum_k \\dpa{f_i\\circ T}{s_k} \\dif s_k \\\\ \\dpa{f_i\\circ T}{s_k} = \\sum_j \\dpa{f_i}{x_j}(T(s))\\cdot \\dpa{x_j}{s_k} \\end{gather*}\\] Donde \\(x_j = T_j(s)\\). Juntando todo tenemos: \\[ \\dif (T^{\\ast} \\omega) = \\sum_{i,j,k} \\dpa{f_i}{x_j}(T(s)) \\dpa{T_j(s)}{s_k} \\df{s_k,T_i} = \\sum_{i,j} \\dpa{f_i}{s_j}(T(s)) \\df{T_j,T_i} = T^{\\ast}(d(\\sum f_i \\dif x_i)) \\] \\(\\dif (T^{\\ast}\\omega) = T^{\\ast}(\\dif \\omega)\\) El cambio a coordenadas polares \\((\\rho,\\theta)\\) se define por la siguiente transformación: \\[T(\\rho,\\theta) =\\left( T_1(\\rho,\\theta),T_2(\\rho,\\theta)\\right) = (\\rho \\cos\\theta,\\rho \\sen\\theta)\\] Vamos a calcular los pull-backs: \\[\\begin{gather*} T^{\\ast}(\\dif x) = \\dif T_1 = \\dpa{T_1}{ρ}\\dif ρ + \\dpa{T_1}{θ}\\dif θ = \\cos θ \\dif ρ - ρ \\sen θ \\dif θ \\\\ T^{\\ast}(\\dif y) = \\dif T_2 = \\dpa{T_2}{ρ}\\dif ρ + \\dpa{T_2}{θ}\\dif θ = \\sen θ \\dif ρ + ρ \\cos θ \\dif θ \\end{gather*}\\] Juntando ahora lo que tenemos: \\[\\begin{align*} \\pb(\\df{x,y}) &amp;= (\\pb \\dif x) \\y (\\pb \\dif y) = \\\\ &amp;= (\\cos θ \\dif ρ - ρ \\sen θ \\dif θ) \\y (\\sen θ \\dif ρ + ρ \\cos θ \\dif θ) = \\\\ &amp;= ρ \\cos^2 θ \\df{ρ,θ} - ρ \\sen^2 θ \\df{θ,ρ} = \\\\ &amp;= \\left(ρ \\cos^2 θ + ρ \\sen^2 θ\\right) \\df{ρ,θ} = \\\\ &amp;= ρ \\df{ρ,θ} \\end{align*}\\] Al final, querremos integrar k-formas en \\(ℝ^N\\) sobre variedades de dimensión \\(k\\). Vamos a partir de un conjunto Ω abierto de \\(\\real^N\\). Sea ω una n-forma definida en un entorno de Ω, es decir \\(\\omega = f(\\gx) \\underbrace{\\dfl{x_1}{x_n}}_{\\text{Elemento de volumen}}\\). Definimos la integral como sigue: Supongamos que tenemos una \\(\\appl{\\Phi}{\\real^K}{\\real^N}\\), tal que \\(\\Phi(\\gor{s}) = \\gx\\). Para que lo de la derecha sea una variedad tenemos que \\(\\Phi\\) tiene que ser regular, homeomorfismo y rango máximo. Supongamos \\(\\omega \\in \\real^N\\), con \\(\\omega\\) una x-forma. ¿Qué pasaría si queremos integrar \\(T^{\\ast}\\omega\\)? Si queremos integrar \\(\\pb{\\omega}\\) en \\(\\real^k, \\omega\\) tiene que ser una k-forma para poder aplicar la definición. Después de haber visto los casos específicos, vamos a ver cómo integrar, de forma genérica, una forma diferencial sobre una variedad diferencial. Sea \\(M\\) una variedad de dimensión k en \\(\\real^N\\). Supongamos que \\((D,\\Phi)\\) es una carta local, es decir: \\(\\appl{\\Phi}{D\\subset\\real^K}{\\real^N}, \\Phi(D)\\subset M\\), siendo Φ una parametrización (\\(\\Phi(\\gor{t}) = \\gx\\)). Sea ω una k-forma definida en \\(ℝ^N\\): \\[\\omega = \\sum_I f_I\\dif x_I; \\quad I=\\{i_1,i_2,...,i_k\\}\\] Por definición: \\[\\begin{equation} \\int_{\\Phi(D)} \\omega = \\int_D \\Phi^{\\ast}\\omega \\label{eqIntFDifVar} \\end{equation}\\] El pull-back nos va a dar una k-forma definida en \\(\\real^k\\). \\[ \\Phi^{\\ast}\\omega =g(\\gor{t})\\dfl{t_1}{t_k} \\] Aplicando esto: \\[ \\int_{\\Phi(d) \\omega} = \\int_D g(\\gor{t})\\dfl{t_1}{t_k} \\] Vamos a identificar la función \\(g\\) remangándonos y haciendo cuentas: \\[ \\Phi^{\\ast} \\omega = \\sum_I f_I\\circ\\Phi \\dif \\Phi_I = \\] Vamos a fijarnos en \\(\\dif \\Phi_I = \\df{\\Phi_{i_1},...,\\Phi_{i_k}}\\), que va a actuar sobre k-vectores, es decir: \\[ \\dif \\Phi_I[\\gv_1,...,\\gv_k] = \\dfl{\\Phi_{i_1}}{\\Phi_{i_k}} [\\gv_1,\\dotsc,\\gv_k] = \\det \\begin{pmatrix} \\dif \\Phi_{i_1}[\\gv_1] &amp; \\cdots &amp; \\dif \\Phi_{i_1}[\\gv_k] \\\\ \\vdots &amp; \\ddots &amp; \\vdots\\\\ \\dif \\Phi_{i_k}[\\gv_1] &amp; \\cdots &amp; \\dif \\Phi_{i_k}[\\gv_k] \\\\ \\end{pmatrix} \\] Vamos a desarrollar uno de los elementos de la matriz (escribiendo \\(\\gw\\) para generalizar a cualquiera de los vectores sobre los que actúa): \\[ \\dif \\Phi_{i_1}[\\gw] = \\sum_{j=1}^k \\left(\\dpa{\\Phi_{i_1}}{t_j} \\dif t_j\\right)[\\gw] = \\sum_{j=1}^k \\dpa{\\Phi_{i_1}}{t_j}w_j = \\pesc{\\grad \\Phi_{i_1},\\gw} \\] Aplicando esto: \\[\\begin{gather*} \\dif \\Phi_I[\\gv_1,...,\\gv_k] = \\det \\begin{pmatrix} \\pesc{\\grad \\Phi_{i_1},\\gv_1} &amp; \\cdots &amp; \\pesc{\\grad \\Phi_{i_1},\\gv_k}\\\\ \\vdots &amp; \\ddots &amp; \\vdots\\\\ \\pesc{\\grad \\Phi_{i_k},\\gv_1} &amp; \\cdots &amp; \\pesc{\\grad \\Phi_{i_k},\\gv_k} \\\\ \\end{pmatrix} = \\det \\left(\\begin{pmatrix} \\grad \\Phi_{i_1} \\rightarrow \\\\ \\cdots \\\\ \\grad \\Phi_{i_k} \\rightarrow \\end{pmatrix} \\cdot \\begin{pmatrix} \\gv_1 &amp; \\cdots &amp; \\gv_k\\\\ \\downarrow &amp; \\cdots &amp; \\downarrow \\end{pmatrix}\\right) = \\\\ = \\det\\begin{pmatrix} \\grad \\Phi_{i_1} \\longrightarrow \\\\ \\cdots \\\\ \\grad \\Phi_{i_k} \\longrightarrow \\end{pmatrix} \\cdot \\det \\begin{pmatrix} \\gv_1 &amp; \\cdots &amp; \\gv_k \\\\ \\downarrow &amp; \\cdots &amp; \\downarrow \\end{pmatrix} \\stackrel{(1)}{=} \\det\\begin{pmatrix} \\grad \\Phi_{i_1} \\longrightarrow \\\\ \\cdots \\\\ \\grad \\Phi_{i_k} \\longrightarrow \\end{pmatrix} \\dfl{t_1}{t_k}[\\gv_1,\\dotsc,\\gv_k] \\end{gather*}\\] (1): Aplicamos que \\(\\dif t_1(\\gv)\\) es la primera coordenada del vector \\(\\gv\\). Un paso intermedio es \\[\\det \\begin{pmatrix} \\dif t_1(\\gv_1) &amp; \\cdots &amp; \\dif t_1(\\gv_k)\\\\ \\vdots &amp; \\ddots &amp; \\vdots\\\\ \\dif t_k(\\gv_1) &amp; \\cdots &amp; \\dif t_k(\\gv_k) \\end{pmatrix} \\] \\[ \\Phi^{\\ast} \\omega = \\sum_I f_I\\circ\\Phi \\dif \\Phi_I = \\overbrace{\\sum_I f_i\\circ\\Phi \\det\\begin{pmatrix} \\grad \\Phi_{i_1} \\longrightarrow \\\\ \\cdots \\\\ \\grad \\Phi_{i_k} \\longrightarrow \\end{pmatrix}}^{\\text{Esta es la g que buscamos}} \\dfl{t_1}{t_k} \\] Aplicando a una integral: \\[\\begin{equation} \\int_{\\Phi(D)} \\omega = \\int_D \\sum_I f_i\\circ\\Phi \\det \\begin{pmatrix} \\grad \\Phi_{i_1} \\longrightarrow \\\\ \\cdots\\\\ \\grad \\Phi_{i_k} \\longrightarrow \\end{pmatrix}\\id{t_1,\\dotsb,t_k} \\label{eqPbIntFDif} \\end{equation}\\] Donde la matriz enorme sería el equivalente al cambio en la medida cuando hacíamos un cambio de coordenadas. Para entender los teoremas de Green, de divergencia (o Gauss) y Stokes en términos de las formas diferenciales, vamos a empezar con el caso básico: el cubo unidad. En \\(ℝ^2\\), el cubo unidad es \\(\\mathcal{Q} = [0,1]\\x[0,1]\\). Para calcular la integral sobre la frontera, tenemos que integrar sobre cada una de las aristas: \\[\\begin{array}{cc} I_{11} =\\{(1,y),y\\in[0,1]\\}&amp;\\text{ Orientación: }\\, +\\\\ I_{21} =\\{(x,1),x\\in[0,1]\\}&amp;\\text{ Orientación: }\\, -\\\\ I_{10} =\\{(0,y),y\\in[0,1]\\}&amp;\\text{ Orientación: }\\, -\\\\ I_{20} =\\{(x,0),x\\in[0,1]\\}&amp;\\text{ Orientación: }\\, +\\\\ \\end{array} \\] Para nombrar las aristas usamos la notación \\(I_{ij}\\), donde \\(i\\) es la variable fija (\\(1=x\\),\\(2=y\\)) y \\(j\\) el valor que toma la variable fija. La orientación está calculada con la regla de la mano izquierda. Me coloco en la frontera mirando hacia la dirección en la que nos movemos. Si la mano izquierda estirada apunta hacia el interior, la orientación es positiva. Si apunta hacia fuera, la orientación es negativa. Sea \\(\\omega = f(x,y)\\dif x + g(x,y)\\dif y\\) la forma diferencial que queremos integrar, cuyo diferencial es \\[\\dif \\omega= \\dpa{f}{y}\\df{y,x} + \\dpa{g}{x}\\df{x,y} = \\left(\\dpa{g}{x} - \\dpa{f}{y}\\right) \\df{x,y}\\] Consideramos \\(\\mathcal{C}^+\\) como la frontera de \\(\\mathcal{Q}\\) orientada positivamente. Vamos a intentar calcular la integral de ω sobre esa frontera. \\[\\begin{align*} \\int_{C^+} \\omega &amp;= \\int_{I_11}\\omega\\, - \\int_{I_20}\\omega\\, - \\int_{I_21}\\omega\\, + \\int_{I_10}\\omega = \\\\ &amp;= \\int_0^1 g(1,y)\\dif y + \\int_0^1 f(x,0)\\dif x - \\int_0^1f(x,1)\\dif x - \\int_0^1 g(0,y)\\dif y = \\\\ &amp;= \\int_0^1 \\left(g(1,y)-g(0,y)\\right) \\dif y - \\int_0^1 \\left( f(x,1)-f(x,0)\\right) \\dif x = \\\\ &amp;= \\int_0^1\\int_0^1 \\dpa{g}{x}(x,y)\\id{x,y} - \\int_0^1\\int_0^1 \\dpa{f}{x}(x,y)\\id{y,x} = \\\\ &amp;= \\iint\\limits_Q\\left( \\dpa{g}{x} - \\dpa{f}{y}\\right)\\id{x,y} = \\\\ &amp;= \\iint\\limits_Q \\dif \\omega \\end{align*}\\] Operando, hemos llegado a que \\[ \\int_{C^{+}} \\omega = \\iint\\limits_Q \\dif \\omega \\] Esto escrito en términos de cálculo II es: \\[ \\int_{C^{+}}(P,Q) = \\iint\\limits_Q \\dpa{Q}{x} - \\dpa{P}{y} \\], que es el . Ahora vamos a hacer algo lo mismo en \\(\\real^3\\), sea \\(Q=[0,1]\\x[0,1]\\x[0,1]\\), trabajando con la normal exterior para las orientaciones. Vamos a distinguir las caras con la notación anterior: \\[\\begin{array}{cc} I_{10} = \\{(0,y,z), y\\in[0,1],z\\in[0,1]\\} &amp; \\text{ Orientación: -} \\\\ I_{11} = \\{(1,y,z), y\\in[0,1],z\\in[0,1]\\} &amp; \\text{ Orientación: +} \\\\ I_{20} = \\{(x,0,z), x\\in[0,1],z\\in[0,1]\\} &amp; \\text{ Orientación: +} \\\\ I_{21} = \\{(x,1,z), x\\in[0,1],z\\in[0,1]\\} &amp; \\text{ Orientación: -} \\\\ I_{30} = \\{(x,y,0), x\\in[0,1],y\\in[0,1]\\} &amp; \\text{ Orientación: -} \\\\ I_{31} = \\{(x,y,1), x\\in[0,1],y\\in[0,1]\\} &amp; \\text{ Orientación: +} \\\\ \\end{array} \\] Las orientaciones están calculadas (según el primer caso) \\[\\left.\\begin{array}{cc} T_y = (0,1,0)\\\\T_z=(0,0,1)\\end{array}\\right\\}\\implies T_y\\x T_z = (1,0,0)\\] Mirando en el dibujo, identificamos que la cara en la que estamos trabajando (en este caso la de detrás) y comprobamos que apunta hacia dentro del cubo (dirección contraria a la normal exterior), y concluimos orientación negativa. Repitiendo el proceso llegamos a la conclusión de: \\[ \\begin{array}{cc} T_y\\x T_z &amp;= (0,0,1)\\\\ T_x\\x T_z &amp;= (0,-1,0)\\\\ T_x\\x T_y &amp;= (1,0,0) \\end{array}\\] Si la suma de los subíndices es par, la orientación es positiva. Si por el contrario es impar, es negativa. Detrás de esta idea hay un teorema que no vamos a ver. Además hay que tener cuidado con el orden en el que se hacen las cosas y se escriben los vectores. Trabajamos con nuestra forma diferencial asociada a un campo \\(\\vf\\): \\[\\omega = F_1(x,y,z)\\df{y,z}+F_2(x,y,z)\\df{y,x}+F_3(x,y,z)\\df{x,y}\\] cuyo diferencial es \\[\\begin{align*} \\dif \\omega &amp;= \\dpa{F_1}{x}\\df{x,y,z} + \\dpa{F_2}{y}\\df{y,x,z} + \\dpa{F_3}{z}\\df{z,x,y} \\\\ &amp;= \\left(\\dpa{F_1}{x}+\\dpa{F_2}{y} + \\dpa{F_3}{z}\\right) \\df{x,y,z} \\end{align*}\\] Vamos a calcular \\[\\int_{dQ^+} \\omega\\] siendo \\(dQ^+\\) la frontera del cubo unidad. \\[\\int_{Q^+} \\omega =\\underbrace{ -\\int_{I_{10}} \\omega + \\int_{I_{11}} \\omega}_{(1)} + \\int_{I_{20}} \\omega - \\int_{I_{21}} \\omega -\\int_{I_{30}} \\omega + \\int_{I_{31}} \\omega\\] Operamos (1) por separado. Aplicando () y la ecuación de la integral de una forma diferencial sobre una superficie () tenemos que \\[\\begin{gather*} -\\int_{I_{10}} \\omega + \\int_{I_{11}} \\omega = \\int_0^1\\int_0^1\\Phi^{\\ast}_{11}\\omega - \\int_0^1\\int_0^1 \\Phi^{\\ast}_{10} \\omega = \\\\ = \\int_0^1\\int_0^1 \\pesc{\\overrightarrow{F}\\circ \\Phi_{11},(1,0,0)}\\id{y,z} -\\int_0^1\\int_0^1 \\pesc{\\overrightarrow{F}\\circ \\Phi_{10},(1,0,0)}\\id{y,z}= \\\\ = \\int_0^1\\int_0^1 F_1(\\Phi_{11}(y,z))-F_1(\\Phi_{10}(y,z))dydz = \\iiint\\limits_Q \\dpa{F_1}{x}\\id{x,y,z} \\end{gather*}\\] Aplicando las mismas cuentas con las que faltan llegamos al para el cubo. \\[\\int_{dQ^+} \\omega = \\int_{Q}\\dif \\omega\\] Las ideas sobre formas diferenciales se traducen en \\(\\real^2\\) en el Teorema de Green y en \\(\\real^3\\) en el Teorema de la divergencia. ¿Dónde queda el Teorema de Stokes? Después de unos ejemplos de aplicación de los teoremas vamos a verlo. Sea \\(\\omega\\) 1-forma en \\(\\real^2\\), y \\(D\\) un conjunto cerrado con frontera orientable. Entonces \\[ \\int_{\\partial D^+} P\\dif x+Q\\dif y = \\iint_D \\dif(P\\dif x+Q\\dif y) = \\int\\int_D \\dpa{Q}{x} - \\dpa{Q}{y}\\id{x,y} \\] Podemos elegir \\((P,Q)\\) de tal modo que \\(\\displaystyle \\dpa{Q}{x}-\\dpa{Q}{y} = 1\\). Entonces el área de \\(D\\) sería \\(\\displaystyle\\int_{\\partial D^+} (P,Q)d\\sigma\\). Podemos aplicar esta idea para hallar el área de la hoja folium de Descartes (imagen ), cuya ecuación es \\[x^3+y^3 = mxy\\] Vamos a parametrizarla, siguiendo la indicación: \\(t = \\frac{y}{x}\\). Se deja como ejercicio para el lector llegar a la fórmula: \\[\\begin{gather*} x=\\frac{mt}{1+t^3}\\\\ y= xt = \\frac{mt^2}{1+t^3} \\end{gather*}\\] Quedando por definir que valores toman los parámetros. En este caso es \\((0,\\infty)\\). Estos valores parametrizan la región cerrada. Podríamos plantearnos para qué valores de \\(t\\) que recorren las ramas que se van a infinito. En \\(t=-1\\), se va a infinito, entonces una de las ramas será \\(t\\in(-1,0)\\) y la otra será \\(t\\in(-\\infty,-1)\\). ¿Que orientación nos da esta parametrización? La idea es ver el vector tangente en el 0. Si es horizontal empezaremos por la rama de abajo. Si es vertical, empezaremos por la rama de arriba \\[\\sigma&#39;(t) = \\left(\\frac{m(1+t^3)-3mt^3}{(1+t^3)^2},\\frac{2mt(1+t^3) - 3mt^4}{(1+t^3)^2}\\right)\\] Podemos comprobar que \\(\\sigma&#39;(t) \\convs[][t][0^+] (m,0)\\). Además, \\(\\sigma&#39;(t) \\convs[][t](0,m)\\), quedando una orientación positiva. \\[ A(D) = \\int_{\\partial D^+} (0,x)d\\sigma = \\int_0^{+\\infty} \\pesc{\\left(0,\\frac{mt}{1+t^3}\\right), \\left(\\ast,\\frac{2mt(1+t^3)-3mt^4}{(1+t^3)^2}\\right)}dt = ... \\] Wolfram dice que el resultado de la integral es \\(\\frac{m^2}{6}\\) y que el área encerrada por el folium de Descartes es también \\(\\frac{m^2}{6}\\) lo que nos hace pensar que está bien planteado y bien resuelto el problema. Hacer lo mismo con la curva \\(x^4+y^4=4xy\\). El área de la hoja contenida en el primer cuadrante. % El teorema decía: \\[ \\int_{\\Gamma^+}\\overrightarrow{F}d\\sigma = \\int \\int_{S^+} \\rot\\overrightarrow{F} dS \\] Siendo \\(S\\) la superficie, \\(\\Gamma\\) la ¿frontera?, tomando la orientación positiva con la normal exterior. \\[ \\left.\\begin{array}{cc} z=x^2+y^2\\\\ z=mx \\end{array} \\right\\} \\equiv \\Gamma \\] Queremos calcular \\(\\displaystyle \\int_{\\Gamma}y \\dif z\\) Esto es lo mismo que calcular la integral del campo \\((0,0,y)\\). El primer paso es \\(\\Gamma\\) Tenemos que la proyección en el plano xy es \\[mx=x^2+y^2 \\equiv \\left(x-\\frac{m}{2}\\right)^2 + y^2 = \\frac{m^2}{4}\\] Viendo los cuadrados lo lógico es pensar en utilizar polares. Llamando \\(x=rsen(\\theta),y=rsen(\\theta)\\) tenemos: \\[\\sigma(\\theta) = \\left(mcos^2(\\theta),mcos(\\theta)sen(\\theta),m^2cos^2(\\theta)\\right)\\,\\,\\,\\theta\\in\\left(\\frac{-\\pi}{2},\\frac{\\pi}{2}\\right)\\] Calculamos el vector tangente para ver en que orientación recorre la curva esta parametrización: \\[\\sigma&#39;(\\theta) = ()\\] \\[\\sigma&#39;(0) = (0,m,0)\\] Suponemos (porque no me lo dicen, que \\(m&gt;0\\)) y nos da la orientación. Como en el enunciado no nos hablan de hacerlo con ninguna orientación, la integral que calculemos será de acuerdo con esta orientación. Vamos con la integral: \\[\\int_{\\Gamma}(0,0,y) d\\sigma =\\int_{\\frac{-\\pi}{2}}^{\\frac{\\pi}{2}}\\pesc{\\underbrace{\\left(0,0,mcos(\\theta)sen(\\theta)\\right)}_{\\overrightarrow{F}(\\sigma(\\theta))},\\ast} d\\theta\\] Como camino alternativo a la fórmula, podemos aplicar el teorema: \\[ = \\int\\int_{D^+} rot(0,0,y)dS\\] Siendo el vector normal el que tenga la tercera componente positiva (razonando geométricamente). Calculamos el rotacional del campo:\\(rot\\overrightarrow{F} =\\left|\\begin{matrix} i&amp;j&amp;k\\\\dx&amp;dy&amp;dz\\\\0&amp;0&amp;y \\end{matrix}\\right| = (1,0,0)\\). Utilizamos la parametrización: \\(S = (x,y,mx), x,y\\in C\\) \\[ = \\int\\int_D^+ rot(0,0,y)dS = \\int \\int_C \\pesc{(1,0,0) ,T_x\\x T_y} dxdy= (1) =\\] \\[ \\int \\int_C \\pesc{(1,0,0),(-m,0,1)} = \\int\\int -m dxdy = -m \\cdot \\, Area (C) = -m\\frac{m^2}{4}\\pi \\] $(1): T_x = (1,0,m); T_y = (0,1,0) $. Otra cosa aplicada es que el vector normal \\((-m,0,1)\\) como la tercera componente es positiva, tenemos que esta parametrización induce la orientación positiva. Partimos, igual que en la sección anterior, del cubo unidad en \\(ℝ^n\\). Contamos además con la aplicación \\(\\appl{\\Phi}{Q}{\\Phi(Q)\\subset\\real^n}\\) que “deforma” ese cubo. Sea \\(\\omega\\) una k-forma en \\(\\real^n\\). Queremos calcular la integral de su diferencial en \\(Φ(Q)\\). \\[ \\int_{\\Phi(Q)} \\dif \\omega = \\int_Q \\Phi^{\\ast}\\dif\\omega = \\int_Q \\dif(\\Phi^{\\ast}\\omega) = \\int_{∂Q^{+}} \\Phi^{\\ast}\\omega \\] Donde \\(∂Q^{+}\\) es la frontera del cubo \\(Q\\) orientada debidamente. El último paso es aplicar el teorema anterior. Sea \\(\\appl{\\sigma}{I}{∂Q}\\). Entonces, \\(\\appl{\\Phi\\circ\\sigma}{I}{\\Gamma}\\), siendo \\(\\Gamma\\) la frontera de \\(\\Phi(Q)\\). Aplicando esto a la integral que estamos calculando: \\[ \\int_{\\Phi(dQ^{+})} \\omega \\equiv \\int{\\Phi\\circ\\sigma(I)} = \\int_I (\\Phi\\circ\\sigma)^{\\ast} \\omega = \\int_I \\sigma^{\\ast}\\left(\\Phi^{\\ast}(\\omega)\\right) = \\int_{\\sigma(I)} \\Phi^{\\ast}\\omega = \\int_{∂Q}\\Phi^{\\ast}\\omega \\] Hemos llegado finalmente a que \\[ \\int_{∂Q^+} \\Phi^{\\ast} \\omega = \\int_{\\Phi(∂Q^+)} \\omega \\] Ahora querríamos dar el siguiente paso: \\[\\int_{\\Phi(∂Q^+)} \\omega = \\int_{∂(\\Phi^{\\ast}(Q))} \\omega \\] Es decir, que la imagen de la frontera sea la frontera de la imagen. Esto no es inmediato: en el cambio a coordenadas polares, por ejemplo, no se cumple a primera vista (ver figura ). Cuando el ángulo (θ) se mantiene fijo y \\(r\\) varía (segmentos azules), la imagen de esa parte de la frontera es un radio de la circunferencia, y cuando \\(r=0\\) y variamos el ángulo (segmento verde) la imagen es un punto. Ahora bien, podemos dividir la región \\(Q\\) en celdas disjuntas, como se puede ver en la figura . De esta forma, las fronteras que sean comunes a varias celdas tendrán orientación incompatible y se anularán al integrar. Esto nos resuelve el problema y podemos enunciar el teorema de Stokes para celdas: Vamos a intentar definir en serio la frontera de objetos en \\(\\real^3\\), que es algo que necesitamos tener realmente muy claro. Hace un tiempo, cuando definíamos una subvariedad, demostramos la existencia de un difeomorfismo Ψ que “aplanaba un trozo” de subvariedad. La frontera de una superficie es el conjunto de los puntos (llamados en clase de Tipo 2) que al aplanar nos quedan en la frontera de un objeto de dimensión 2 (ver imagen ). Una vez aclarado el concepto de frontera, pasamos a demostrar el teorema de Stokes. La versión de este teorema vista en clase de prácticas (que es una versión más práctica) Además, para calcular el potencial se puede utilizar cualquiera de estas 3 fórmulas: \\[\\begin{gather*} \\int_{Γ_1}\\vf=\\int_0^x F_1(t,0,0)\\dif t + \\int_0^y F_2(x,s,0)\\dif s+ \\int_0^z F_3(x,y,r)\\dif r \\\\ \\int_{Γ_2}\\vf = \\int_0^y F_2(0,t,0)\\dif t + \\int_0^z F_3(0,y,s)\\dif s+ \\int_0^x F_1(x,y,r)\\dif r \\\\ \\int_{Γ_3}\\vf = \\int_0^x F_1(t,0,0)\\dif t + \\int_0^z F_3(x,0,s)\\dif s+ \\int_0^y F_1(x,r,z)\\dif r \\\\ \\end{gather*}\\] 12.1 Integración 12.2 Aplicaciones primitivas 12.3 Cambio de variables 12.4 Formas diferenciales 12.5 Cadenas y símplices 12.6 Teorema de Stoke 12.7 Formas cerradas y formas exactas 12.8 Análisis vectorial "]
]
