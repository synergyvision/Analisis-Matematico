[
["teoria-de-probabilidades.html", "Capítulo 41 Teoría de probabilidades 41.1 Variables aleatorias 41.2 Independencia 41.3 Esperanza condicional 41.4 Sucesiones de variables aleatorias independientes 41.5 Martingalas a tiempo discreto 41.6 Procesos estocásticos 41.7 Movimiento browniano 41.8 Integración estocástica 41.9 Aplicación a las finanzas", " Capítulo 41 Teoría de probabilidades ##Conjuntos y funciones \\(\\sigma\\)-aditivas} Sea un conjunto \\(\\Omega\\), y sea \\(\\mathcal{A}\\) una \\(\\sigma\\)-álgebra sobre \\(\\Omega\\). Se dice que \\(\\mathcal{A}\\) es una \\(\\sigma\\)-álgebra si cumple las siguientes propiedades: Es decir, una \\(\\sigma\\)-álgebra es una clase de conjuntos cerrada para las operaciones complementario y unión numerable. Existen una serie de propiedades inmediatas derivadas de las propiedades que definen a la \\(\\sigma\\)-álgebra:\\ \\(\\emptyset \\in \\mathcal{A}\\)\\ \\(\\mathcal{A}\\) es cerrada para la operación intersección numerable. Al par (\\(\\Omega\\), \\(\\mathcal{A}\\)) se le llama espacio medible, y a los conjuntos que pertenecen a \\(\\mathcal{A}\\) se les denomina conjuntos medibles. Si tomamos la relación de inclusión entre conjuntos (\\(\\subseteq\\)) como una relación de orden, podemos hablar sin ambiguedad de sucesiones monótonas. En este sentido, una sucesión creciente de conjuntos es una sucesión \\(\\{A_n\\}_{n \\in \\mathbb{N}}\\) en la que se cumple que \\(A_i \\subseteq A_{i+1}, \\forall i \\in \\mathbb{N}\\). De forma análoga se puede definir sucesión decreciente de conjuntos.\\ Existe una forma intuitiva de definir el límite de una sucesión monótona de conjuntos. En particular, el límite de una sucesión creciente de conjuntos \\(\\{A_n\\}_{n \\in \\mathbb{N} }\\) se puede definir como \\[\\lim_{n\\to\\infty} A_n = \\bigcup_{k \\in \\mathbb{N}}^{\\infty} A_k\\] Esta definición aprovecha la relación de orden entre los conjuntos de la sucesión para afirmar que si un elemento está en el último conjunto de la sucesión, entonces está en todos los anteriores, y por tanto en todos, por ello se puede utilizar una intersección numerable (que está bien definida) para formalizar el concepto.\\ Con una intuición análoga se define el límite de una sucesión decreciente de conjuntos. Si \\(\\{A_n\\}_{n\\in\\mathbb{N}}\\) es una sucesión decreciente de conjuntos, entonces: \\[ \\lim_{n\\to\\infty} A_n = \\bigcap_{k\\in\\mathbb{N}}^{\\infty} A_k \\] No solo se puede hablar de límites en sucesiones monótonas. Para definir los límites en sucesiones arbitrarias de conjuntos tenemos que recurrir a los conceptos de límite inferior y límite superior. La intuición de estos límites superior e inferior pasan por el concepto de las colas de la sucesión.\\ Dada una sucesión de conjuntos \\(\\{A_n\\}_{n\\in\\mathbb{N} }\\) podemos considerar el conjunto \\[ B_n = \\bigcap_{k=n}^{\\infty} A_k \\] y este conjunto contiene aquellos elementos que están en los \\(A_k\\) para \\(k \\geq n\\). Es fácil probar que la sucesión \\(\\{B_n\\}_{n\\in\\mathbb{N}}\\) es una sucesión creciente de conjuntos, y por tanto se puede obtener el límite \\(\\lim_{n\\to\\infty} B_n\\). Informalmente, ese límite es un conjunto que contiene a todos los elementos de \\(A_n\\) que están en todos los conjuntos \\(A_k\\) a partir de cierto \\(n\\in\\mathbb{N}\\). Definimos el límite inferior de \\(A_n\\) como \\[ \\liminf A_n = \\lim_{n\\to\\infty} B_n = \\bigcup_{n\\in\\mathbb{N}} \\bigcap_{k=n}^{\\infty} A_n \\] Análogamente, podríamos definir la sucesión de conjuntos \\(\\{C_n\\}_{n\\in\\mathbb{N}}\\) como \\[ C_n = \\bigcup_{k=n}^{\\infty} A_n \\] Cada \\(C_n\\) contiene todos los elementos que están presentes en algún \\(A_k\\) para \\(k \\geq n\\). Es fácil también ver que la sucesión \\(\\{C_n\\}_{n\\in\\mathbb{N}}\\) es una sucesión decreciente de conjuntos, y por tanto su límite también está bien definido. Se puede definir entonces el límite superior de \\(\\{A_n\\}_{n\\in\\mathbb{N}}\\) como \\[ \\limsup A_n = \\lim_{n\\to\\infty} C_n = \\bigcap_{n\\in\\mathbb{N}} \\bigcup_{k=n}^{\\infty} A_n \\] Informalmente se puede pensar en este límite superior de \\(A_n\\) como el conjunto de los elementos que están en infinitos conjuntos de la sucesión.\\ A partir de estas definiciones, es fácil comprobar que \\[ \\liminf A_n \\subseteq \\limsup A_n \\] Diremos que una sucesión de conjuntos tiene límite si su límite inferior y superior coinciden, y el límite tendrá como valor efectivamente el de estos límites. Es decir: \\[ \\lim A_n = \\liminf A_n = \\limsup A_n \\] en caso de que límite superior e inferior coincidan. Una vez definidos los conceptos sobre conjuntos con los que vamos a trabajar, pasamos a definir las funciones sobre conjuntos. Vamos entonces a definir lo que es una función de conjunto. Sean los espacios medibles (\\(\\Omega\\), \\(\\mathcal{A}\\)) y(\\(\\Omega&#39;\\), \\(\\mathcal{A}&#39;\\)), definimos la función: \\[ X: \\mathcal{A} \\to \\mathcal{A}&#39;\\] \\[ A \\longrightarrow X(A)\\] A raíz de esta definición podemos definir también lo que se conoce como función inversa. Dada una función \\(X\\), la función inversa de \\(X\\), \\(X^{-1}\\), asigna a cada conjunto \\(A&#39; \\in \\mathcal{A}&#39;\\) el conjunto \\(A \\in \\mathcal{A}\\) tal que \\(X(A) = A&#39;\\). La propiedad básica que cumplen las funciones inversas es que preservan las operaciones e inclusiones de conjuntos. Sea un conjunto \\(\\Omega\\) y una \\(\\sigma\\)-álgebra \\(\\mathcal{A}\\) sobre \\(\\Omega\\). Definimos la función de conjunto: \\[\\varphi : \\mathcal{A} \\rightarrow \\mathbb{R}\\] Se dice que \\(\\varphi\\) es aditiva si \\(\\varphi(\\displaystyle\\sum_{1}^{n}A_k)=\\displaystyle\\sum_1^n\\varphi(A_k)\\)\\ Se dice que \\(\\varphi\\) es \\(\\sigma\\)-aditiva si \\(\\varphi(\\displaystyle\\sum_1^\\infty A_k)=\\displaystyle\\sum_1^\\infty \\varphi(A_k)\\) Sea \\(\\varphi\\) definida como antes. Se dice que \\(\\varphi\\) es si \\(\\varphi(A \\cup B) \\leq \\varphi(A) + \\varphi(B)\\) Una vez introducido el concepto de límite para una sucesión de conjuntos, vamos a tratar de definir la continuidad para funciones de conjunto. Tendremos tres tipos de continuidad, cada uno relacionado con un tipo de sucesiones de conjuntos de las que hemos definido anteriormente. En esta sección trabajaremos con una función \\(\\varphi : \\Omega \\to \\Omega&#39;\\)\\ Diremos que \\(\\varphi\\) es continua por abajo si cumple que, dada una sucesión creciente de elementos \\(A_n \\uparrow A\\), se tiene que \\[ \\lim \\varphi (A_n) = \\varphi (A) \\] Por otra parte, diremos que \\(\\varphi\\) es continua por arriba si cumple que dada una sucesión decreciente de elementos \\(A_n \\downarrow A\\), se tiene que \\[ \\lim \\varphi (A_n) = \\varphi (A)\\] Por último, diremos que una función es continua si lo es por arriba y por abajo. Una vez demostrado este teorema, vamos a ver un teorema que nos relaciona las propiedades del supremo e ínfimo de una función \\(\\sigma\\)-aditiva con los conjuntos sobre los que está dicha función definida: Una función de conjuntos \\(\\mu^\\circ\\) es una medida si verifica: A la tupla (\\(\\Omega\\), \\(\\mathcal{A}\\), \\(\\mu_{\\mathcal{A}}\\)) se le denomina espacio de medida.\\ Una medida exterior es una función de conjuntos positiva y \\(\\sigma\\)-subaditiva, es decir, no se cumple la primera propiedad. La \\(\\sigma\\)-subaditividad implica que \\(\\mu(A \\cup B) \\leq \\mu(A) + \\mu(B)\\).\\ Para que una medida exterior fuera una medida tendría que ser \\(\\sigma\\)-aditiva. Es decir, la falla la primera condición. Sí que es positiva ya que \\(\\mu^\\circ(\\emptyset)=0\\) y es creciente. Esta medida exterior se aplica a cualquier conjunto. Va a haber unos subconjuntos en los que la función se comporte como si fuera aditiva.\\ Una vez definido el concepto de medida, vamos a dar ahora el de probabilidad. Una probabilidad \\(\\mathcal{P}\\) sobre un espacio medible (\\(\\Omega\\), \\(\\mathcal{A}\\)) es una medida que además cumple que \\(\\mathcal{P}(\\Omega)=1\\). Por tanto, tiene las siguientes propiedades:\\ \\(\\mathcal{P}(\\emptyset)=0\\)\\ \\(\\forall A \\in \\mathcal{A}, 0 \\leq \\mathcal{P}(A) \\leq 1\\)\\ Es una función \\(\\sigma\\)-aditiva\\ De forma análoga al concepto de espacio de medida, podemos definir ahora el de espacio probabilístico. Un espacio probabilístico es una tupla formada por un conjunto \\(\\Omega\\), una \\(\\sigma\\)-álgebra sobre ese conjunto, \\(\\mathcal{A}\\), y una función de probabilidad \\(\\mathcal{P}\\). Una vez vistas las definiciones anteriores de medida y medida exterior, vamos a ver un teorema fundamental, que nos servirá para justificar la forma en la que haremos el cálculo de probabilidades a posteriori. Veamos dos lemas antes que nos serán necesarios para la demostración del teorema principal.\\ Un conjunto \\(A\\in S(\\Omega)\\) es \\(\\mu^\\circ\\)-medible si se cumple que \\(\\mu^\\circ(D) \\geq \\mu^\\circ(AD)+\\mu^\\circ(A^cD), \\forall D \\in S(\\Omega)\\)\\ Una extensión exterior \\(\\mu^\\circ\\) de una medida \\(\\mu\\) se define como: \\[\\mu^\\circ (A) = \\inf \\sum_j (A_j), \\quad A \\subset \\cup A_j,\\quad recubrimiento \\] Una vez definidos los conceptos sobre espacios de medida y espacios probabilísticos, vamos a aproximarnos al concepto de función medible. Para ello, daremos dos definiciones de función medible, para demostrar más adelante que estas dos definiciones son equivalentes. Empecemos con la definición constructiva de función medible. Dado que nos interesa que el codominio sea \\(\\mathbb{R}\\), trabajaremos con funciones definidas entre un espacio medible (\\(\\Omega\\), \\(\\mathcal{A}\\)) y (\\(\\mathbb{R}\\), \\(\\mathcal{B}\\)), donde \\(\\mathcal{B}\\) representa la \\(\\sigma\\)-álgebra de Borel.\\ Primero, se define la función puntual \\(X: \\Omega \\to \\mathbb{R}\\), que asigna a cada \\(\\omega \\in \\Omega\\) un número \\(x = X(\\omega)\\) único. Llamaremos a esta función variable aleatoria. Utilizaremos de aquí en adelante la siguiente notación: Sea entonces la función \\(X = \\displaystyle \\sum_j x_jI_{A_j}\\), donde \\(A_j\\) son conjuntos medibles y \\(I_{A_j}\\) denota la función indicadora de dicho conjunto. Estas funciones se llaman funciones elementales, y cuando el número de valores distintos que toma la función \\(X\\) es finito, se conocen como funciones simples. Entonces, la definición constructiva de función medible es la que sigue:\\ Una función es medible si es límite de una sucesión de funciones simples \\(\\{X_n\\}\\) convergentes.\\ Esta definición que hemos dado es constructiva, y por tanto, nos será muy útil para la definición constructiva de las integrales. No obstante, para enunciar y demostrar las propiedades de las funciones medibles, suele ser más útil la definición descriptiva siguiente:\\ Sea una función \\(\\varphi : \\mathcal{A} \\rightarrow \\mathcal{B}\\). Se dice que \\(\\varphi\\) es medible si \\(\\forall B \\in \\mathcal{B} \\Rightarrow \\varphi^{-1}(B) \\in \\mathcal{A}\\). Es decir, una función se dice medible si la imagen inversa de todo conjunto medible es medible.\\ No obstante, se puede dar, a raíz de esta, otra definición más económica:\\ Para la definición anterior, es suficiente con exigir la medibilidad de las imágenes inversas de los elementos de una subclase \\(\\alpha\\) para la cual la \\(\\sigma\\)-álgebra minimal sobre \\(\\alpha\\) sea \\(\\mathcal{B}\\)\\ Veamos ahora que las dos definiciones que hemos dado son equivalentes. Vamos a establecer ahora criterios que nos permitan comparar variables aleatorias. Dado un espacio de probabilidad (\\(\\Omega\\), \\(\\mathcal{A}\\), \\(\\mathcal{P}\\)), se dice que dos variables aleatorias son equivalentes si: \\[ X\\mathcal{R}Y \\Leftrightarrow \\mathcal{P}[X = Y] = 1\\] Análogamente: \\[X(\\omega) = Y(\\omega) \\forall \\omega \\in \\Omega \\setminus \\Lambda, \\mathcal{P}(\\Lambda) = 0\\] Si \\(P[|X_n- X| \\geq \\varepsilon]\\rightarrow 0\\), entonces se dice que \\(X_n\\stackrel{\\mathbb{P}}{\\longrightarrow} X\\), es decir, \\(X_n\\) converge en probabilidad a \\(X\\)\\ Se dice que una variable aleatoria \\(X\\) converge uniformemente en \\(u\\) si se cumple que \\(\\mathcal{P}[\\mid X_{n+u} - X_n \\mid \\geq \\varepsilon] \\to 0\\) Una sucesión de variables aleatorias, \\({ X_n }\\) , converge con probabilidad 1, o de forma casi segura, a una variable aleatoria \\(X\\) ( que puede degenerar en una constante K) cuando se cumple que: \\[P(\\lim_{n\\rightarrow\\infty}X_n=X)=1\\] De esta forma interpretamos que \\(X_n\\stackrel{c.s}{\\longrightarrow}X\\) cuando la probabilidad de que en el límite la sucesión de variables aleatorias y aquella a la que converge sean iguales es uno Para el cálculo de probabilidades, nos será muy útil el concepto de integral sobre funciones de conjunto. Este concepto nos servirá para calcular lo que se conoce como la esperanza matemática de una variable aleatoria \\(X\\). En este apartado trabajaremos sobre el espacio de probabilidad \\((\\Omega, \\mathcal{A}, \\mathcal{P})\\). Comenzaremos definiendo la integral para las funciones simples, para dar luego una definición de integral para funciones no negativas y por último para funciones cualesquiera.\\ Sea entonces \\(\\{A_k\\} \\in \\mathcal{A}\\), tal que \\(\\displaystyle \\sum_k A_k = \\Omega\\), partición medible del espacio. Sea entonces la función simple \\(X = \\displaystyle \\sum_{j=1}^m x_jI_{A_j}, x_j \\geq 0\\). La integral de la función \\(X\\) se define como: \\[\\int_{\\Omega} X d\\mathcal{P} = \\sum_{j=1}^m x_j\\mathcal{P}_{A_j}\\] Ahora, para cualquier función no negativa \\(X\\), se define la integral de la función como: \\[\\int_{\\Omega} X d\\mathcal{P} = \\lim \\int_{\\Omega}X_n d \\mathcal{P}\\] Donde \\(\\{X_{n}\\} \\to X\\). Finalmente, la integral en \\(\\Omega\\) de una función medible \\(X\\) se define como: \\[\\int_{\\Omega} X d\\mathcal{P} = \\int_{\\Omega}X^{+} d\\mathcal{P} - \\int_{\\Omega} X^{-} d\\mathcal{P}\\] donde \\(X^{+} = XI_{[X\\geq0]}\\) y \\(X^{-} = -XI_{[X&lt;0]}\\). Si \\(\\displaystyle \\int_{\\Omega}Xd\\mathcal{P}\\) es finita, es decir, si los dos términos de la diferencia anterior son finitos, entonces se dice que \\(X\\) es integrable en \\(\\Omega\\). Ahora, una vez definida la integral, vamos a ver algunas de sus propiedades. Tenemos primero una serie de propiedades relacionadas con la aditividad de la integral. Sean \\(X,Y\\) dos funciones medibles, entonces (no se demostrarán las propiedades triviales):\\ \\(\\displaystyle \\int (X+Y)d\\mathcal{P} = \\int Xd\\mathcal{P} + \\int Yd\\mathcal{P}\\)\\ \\(\\displaystyle \\int_{A+B} X d\\mathcal{P} = \\int_A X d\\mathcal{P} + \\int_B X d \\mathcal{P}\\)\\ \\(\\displaystyle \\int cXd\\mathcal{P} = c\\int Xd\\mathcal{P}\\)\\ Veamos ahora algunas propiedades relacionadas con el orden:\\ \\(X \\geq 0 \\rightarrow \\displaystyle \\int X d\\mathcal{P} \\geq \\int 0 = 0\\)\\ \\(X \\geq Y \\rightarrow \\displaystyle \\int X d\\mathcal{P} \\geq \\int Y d\\mathcal{P}\\)\\ \\(\\displaystyle X \\stackrel{c.s}{=} Y \\rightarrow \\int X d\\mathcal{P} = \\int Y d\\mathcal{P}\\)\\ Dado un espacio probabilístico \\((\\Omega, \\mathcal{A}, P)\\) y una v.a. \\(X\\), se define la esperanza matemática de \\(X\\) como: \\[E(X)=\\int_{\\Omega}XdP=\\int_{\\omega \\in \\Omega}{X(\\omega)dP(\\omega)}\\] \\\\ La esperanza matemática se define de forma distinta si estamos trabajando con una v.a. discreta o continua. En el caso de una v.a. discreta, sea \\(p(x_i)\\) su función de probabilidad. Definimos la esperanza matemática como: \\[E(X)=x_1p(X=x_1)+\\ldots + x_n p(X=x_n)=\\sum_{i=1}^{n}{x_i p(x_i)}\\] En el caso de una v.a. continua, sea \\(f(x)\\) la función de densidad. Definimos la esperanza matemática como: \\[E(X)=\\int_{-\\infty}^{+\\infty} {xf(x)dx}\\] Una vez vista la definición de integral y esperanza matemática y algunas de sus propiedades, vamos a enunciar y demostrar un teorema de convergencia que nos será de mucha utilidad para el estudio de variables aleatorias. Veamos su enunciado y demostración: Veamos ahora un resultado que nos da información sobre el límite superior e inferior de una sucesión de variables aleatorias, en caso de que estas estén acotadas por variables aleatorias integrables Vamos a ver algunas desigualdades que nos permitirán simplificar el cálculo de carácterísticas asociadas a variables aleatorias.\\ \\ Dado un espacio probabilístico (\\(\\Omega\\), \\(\\mathcal{A}\\), \\(\\mathcal{P}\\)) y una variable aleatoria \\(X\\), se define el momento r-ésimo o de orden r de la variable \\(X\\) a: \\[ EX^r = \\int X^r \\, d \\mathcal{P} \\] Dicho momento existe si \\(E|X|^r &lt; \\infty\\) \\(E|XY| \\leq \\left(E|X|^r \\right)^{\\frac{1}{r}} \\left(E|Y|^s \\right)^{\\frac{1}{s}}\\) con \\(r&gt;s\\) ; $ +=1$ \\(E|XY|\\leq \\left(E|X|^2 \\right)^{\\frac{1}{2}} \\left(E|Y|^2 \\right)^{\\frac{1}{2}}\\) Si \\(r \\geq 1 \\Rightarrow (E|X+X&#39;|^r)^{\\frac{1}{r}} \\leq \\left(E|X|^r \\right)^{\\frac{1}{r}} + \\left(E|X&#39;|^r \\right)^{\\frac{1}{r}}\\) Sea \\(X\\) una v.a. y sea \\(g\\) una función boreliana. Entonces se tiene: Vamos a demostrar que en efecto se cumple la desigualdad básica: Se dice que una sucesión de variables aleatorias \\(X_n\\) converge en r-medida a \\(X\\) si: \\[ E|X_n - X|^r \\to 0\\] Lo notamos como \\(X_n \\stackrel{r}{\\rightarrow} X\\) Función puntual que se define sobre la recta real, no negativa, no decreciente, continua por la izquierda y que cumple que \\(F(-\\infty) = 0, F(+\\infty) = 1\\)\\ Se conoce como distribución inducida por la variable aleatoria \\(X\\) a (\\(\\mathbb{R}\\), \\(\\mathcal{B}\\), \\(\\mathcal{P}^X\\)), donde la medida de probabilidad \\(\\mathcal{P}^X\\) se define como: \\[ \\mathcal{P}^X(B) = \\mathcal{P}(X^{-1}(B)), \\, \\forall B \\in \\mathcal{B} \\] Tenemos entonces que: Llamamos función generatriz de momentos de la variable aleatoria \\(X\\) a la función: \\[ M_X(t) = E(e^{tX}); \\, t \\in \\mathbb{R} \\] Dada una variable aleatoria \\(\\mathbb{X}\\) continua, definimos su función característica como: \\[\\varphi_X(t)=E(e^{itX})=\\int_{-\\infty}^{\\infty}e^{itx}f_{X}(x)=E(cos(tX))+iE(sen(TX))\\] Se dice que los eventos \\(A_t\\) son independientes si para todo subconjunto finito \\((t_i,\\ldots ,t_n)\\) se tiene que: \\[P\\bigcap_{k=1}^n A_{tk}=\\displaystyle\\prod_{k=1}^{n}P\\, A_{tk}\\] De hecho, el concepto de independencia es relativo a la familia de clases. Una clase de eventos se dice independiente si sus eventos son independientes. Esto tiene tres aplicaciones fundamentales: Una familia de variables aleatorias \\(X_{T_s}=\\{ X_t \\, , \\, t\\in T_s \\}\\) induce \\(\\sigma\\) algebras \\(\\mathcal{B}(X_{T_s})\\) de eventos Las variables aleatorias \\(X_t\\, , \\, t\\in T\\) son independientes si para cada clase finita \\((S_{t_1},\\ldots , S_{t_n})\\) de conjuntos de Borel en R: \\(P\\bigcap_{k=1}^{n}[X_{t_k}\\in S{t_k}]=\\displaystyle\\prod_{k=1}^n P[X_{t_k}\\in S_{t_k}]\\) 41.1 Variables aleatorias 41.2 Independencia 41.3 Esperanza condicional 41.4 Sucesiones de variables aleatorias independientes 41.5 Martingalas a tiempo discreto 41.6 Procesos estocásticos 41.7 Movimiento browniano 41.8 Integración estocástica 41.9 Aplicación a las finanzas "]
]
